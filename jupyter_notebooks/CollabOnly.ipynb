{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Notebook for Google Collab**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "# This notebook is for use in Google Collab only, compiled in a single workflow.\n",
        "\n",
        "## Objectives\n",
        "Answer Business requirement 2: Binary Classification using Convolutional Neural Networks\n",
        "\n",
        "* predict if a given leaf is infected or not judging by the presence of powdery mildew.\n",
        "* use the CNN to map relationships between features and labels.\n",
        "* build a binary classifier and generate reports.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/cherry-leaves-dataset/cherry-leaves/train\n",
        "* inputs/cherry-leaves-dataset/cherry-leaves/test\n",
        "* inputs/cherry-leaves-dataset/cherry-leaves/validation\n",
        "* image shape embeddings pickle file\n",
        "\n",
        "## Outputs\n",
        "TODO\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ANNOTATE MODEL VERSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v3'  # change as needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import regular packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "### Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# manually upload kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# allow kaggle.json access\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
        "DestinationFolder = \"inputs/cherry-leaves-dataset\"  # creates new dir/dir\n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(DestinationFolder + '/cherry-leaves.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall(DestinationFolder)\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set input directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data_dir = 'inputs/cherry-leaves-dataset/cherry-leaves'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
        "    print('Old version is already available, create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gather labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    labels = os.listdir(train_path)\n",
        "except:\n",
        "    labels = ['healthy', 'powdery_mildew']\n",
        "\n",
        "print(f\"Project Labels: {labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load image shape embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "version_im = 'v1'  # original (should remain unchanged)\n",
        "\n",
        "try:\n",
        "    # Import saved image shape embedding pickle file\n",
        "    image_shape = joblib.load(filename=f\"outputs/{version_im}/image_shape.pkl\")\n",
        "\n",
        "except:\n",
        "    # for google collab\n",
        "    image_shape = (256, 256, 3)\n",
        "\n",
        "finally:\n",
        "    print(image_shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate image files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "Uncomment if using google collab\n",
        "\n",
        "def remove_non_image_files(my_data_dir):\n",
        "    print('Removing non image files...\\n')\n",
        "    image_extension = ('.png', '.jpg', 'jpeg')\n",
        "    folders = os.listdir(my_data_dir)\n",
        "    for folder in folders:\n",
        "        files = os.listdir(f'{my_data_dir}/{folder}')\n",
        "        # print files\n",
        "        non_image = []\n",
        "        image_count = []\n",
        "        for given_file in files:\n",
        "            try:\n",
        "                if not given_file.lower().endswith(image_extension):\n",
        "                    file_location = f'{my_data_dir}/{folder}/{given_file}'\n",
        "                    os.remove(file_location) # remove non image file\n",
        "                    non_image.append(1)\n",
        "                else:\n",
        "                    image_count.append(1)\n",
        "                    pass\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "        print(f'Folder: {folder} has - {len(image_count)} image files')\n",
        "        print(f'Folder: {folder} has - {len(non_image)} non image files, which have been removed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "remove_non_image_files('inputs/cherry-leaves-dataset/cherry-leaves')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split train, val, test sets with dirs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
        "\n",
        "    # confirm ratios total 1.0\n",
        "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
        "        print('Ratios should total 1.0.')\n",
        "        print('You entered:\\n')\n",
        "        print(f'Train radio: {train_set_ratio}')\n",
        "        print(f'Validation radio: {validation_set_ratio}')\n",
        "        print(f'Test radio: {test_set_ratio}')\n",
        "        return \n",
        "\n",
        "    # get classes labels\n",
        "    labels = os.listdir(my_data_dir)  # expect only folder name\n",
        "    if 'test' in labels:\n",
        "        pass\n",
        "    else:\n",
        "        try:\n",
        "            # create train, test folders with classes labels sub-folder\n",
        "            for folder in ['train', 'validation', 'test']:\n",
        "                for label in labels:\n",
        "                    os.makedirs(name=f'{my_data_dir}/{folder}/{label}')\n",
        "            \n",
        "            for label in labels:\n",
        "\n",
        "                files = os.listdir(f'{my_data_dir}/{label}')\n",
        "                random.seed(42)\n",
        "                random.shuffle(files)\n",
        "\n",
        "                train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "                validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "\n",
        "                count = 1\n",
        "                for file_name in files:\n",
        "                    if count <= train_set_files_qty:\n",
        "                        # move given file to train set\n",
        "                        shutil.move(f'{my_data_dir}/{label}/{file_name}',\n",
        "                                    f'{my_data_dir}/train/{label}/{file_name}')\n",
        "                    elif count <= (train_set_files_qty + validation_set_files_qty):\n",
        "                        # move a given file to the validation set\n",
        "                        shutil.move(f'{my_data_dir}/{label}/{file_name}',\n",
        "                                    f'{my_data_dir}/validation/{label}/{file_name}')\n",
        "                    else:\n",
        "                        # move given file to test set\n",
        "                        shutil.move(f'{my_data_dir}/{label}/{file_name}',\n",
        "                                    f'{my_data_dir}/test/{label}/{file_name}')\n",
        "                    \n",
        "                    count += 1\n",
        "\n",
        "                os.rmdir(f'{my_data_dir}/{label}')\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "    \n",
        "    print('Done!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_train_validation_test_images(\n",
        "    my_data_dir='inputs/cherry-leaves-dataset/cherry-leaves',\n",
        "    train_set_ratio=0.7,\n",
        "    validation_set_ratio=0.1,\n",
        "    test_set_ratio=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Review class distribution\n",
        "\n",
        "* across whole dataset\n",
        "* per train, test, and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_freq = pd.DataFrame([])\n",
        "total_images_count = 0\n",
        "\n",
        "# gather info\n",
        "for folder in ['train', 'validation', 'test']:\n",
        "    for label in labels:\n",
        "\n",
        "        path = my_data_dir + '/' + folder + '/' + label\n",
        "        \n",
        "        image_count = int(len(os.listdir(path)))\n",
        "        total_images_count += image_count\n",
        "\n",
        "        try:\n",
        "            df_freq = df_freq.append(pd.Series({'Set': folder,'Label': label,'Frequency': image_count}), ignore_index=True )\n",
        "            print(f\"* {folder}- {label}: {image_count} images\\n\")\n",
        "        except:\n",
        "            # for google collab functionality \n",
        "            df_freq = df_freq.concat(pd.Series({'Set': folder,'Label': label,'Frequency': image_count}), ignore_index=True )\n",
        "            print(f\"* {folder}- {label}: {image_count} images\\n\")\n",
        "\n",
        "\n",
        "print(f'{total_images_count} images total')\n",
        "print('--------')\n",
        "\n",
        "### plot class distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Set', y='Frequency', hue='Label', data=df_freq)\n",
        "plt.title('Class Distribution')\n",
        "plt.savefig(f'{file_path}/class_distribution.png', bbox_inches='tight', dpi=600)\n",
        "plt.show()\n",
        "print('\\n')\n",
        "\n",
        "print('--------')\n",
        "\n",
        "# confirm percentages of dataset\n",
        "df_freq.set_index('Label', inplace=True)\n",
        "df_freq['Percent of DataSet'] = round(df_freq['Frequency'] / total_images_count * 100)\n",
        "\n",
        "print(df_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can confirm that train, validation and test set percentages of dataset are split as expected, and that there are equal amounts of both classes (healthy and powdery_mildew) in each set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define image data generator, initialize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This function generates batches of image data with real-time data augmentation.\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Initialize\n",
        "augmented_image_data = ImageDataGenerator(rotation_range=30,\n",
        "                                          width_shift_range=0.15,\n",
        "                                          height_shift_range=0.15,\n",
        "                                          brightness_range=[0.8, 1.2],\n",
        "                                          shear_range=0.1,\n",
        "                                          zoom_range=0.2,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=True,\n",
        "                                          fill_mode='nearest',\n",
        "                                          rescale=1./255\n",
        "                                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define batch size\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Augment TRAINING image dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='binary',\n",
        "                                                     shuffle=True,\n",
        "                                                     seed=42\n",
        "                                                     follow_links=False\n",
        "                                                     )\n",
        "\n",
        "\n",
        "train_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rescale validation image dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='binary',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "validation_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rescale test image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='binary',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "\n",
        "test_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot augmented training images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(5):\n",
        "    try:\n",
        "        img, label = train_set.next()\n",
        "    except:\n",
        "        # for google collab functionality\n",
        "        img, label = next(train_set)\n",
        "\n",
        "    print(f'{img.shape}\\n')  # expect: (20, 256, 256, 3)\n",
        "    plt.imshow(img[0])\n",
        "    print('--------------')\n",
        "    plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot augmented validation and test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(5):  \n",
        "    try:\n",
        "        img, label = validation_set.next()\n",
        "    except:\n",
        "        # for google collab functionality\n",
        "        img, label = next(validation_set)\n",
        "    print(f'{img.shape}\\n')\n",
        "    plt.imshow(img[0])\n",
        "    print('--------------')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Observations\n",
        "Augmented validation and test images have been standardized between 0 to 255 pixels. As you can see, the images are ugmented and are ready to be used for developing and training a CNN model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save class indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ML Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Import model packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO remove? for google collab functionality\n",
        "# !pip install tensorflow\n",
        "# !pip install keras_tuner \n",
        "\n",
        "# TODO v3:\n",
        "# TODO import keras_tuner as kt \n",
        "# TODO import Adam?\n",
        "# TODO add check for tf version for continuity between collab and other environments\n",
        "# TODO uncomment to find collab dependencies\n",
        "# TODO remove? !pip freeze > collab_requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(f'tf version: {tf.__version__}')\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO v3 add hp as param if using hypertuner\n",
        "def create_tf_model():\n",
        "    \"\"\"\n",
        "    Creates a CNN model for binary classification of leaf images\n",
        "    TODO add to readme instead:\n",
        "    Documentation of process: \n",
        "\n",
        "    v1:\n",
        "    - 4 convolution layers, c.7m trainable params. Early stopping included. No batch normalisation. Batch size 20.\n",
        "    - bizarre results with 100% accuracy: concerns of data leakage.\n",
        "\n",
        "    v2:\n",
        "    - no early stopping to observe model development over longer period of epochs (25)\n",
        "    - removed one convolution layer: 4 may have been too complex for the small dataset\n",
        "        - instead, v2 convolution layer 3 has largest number of filters\n",
        "    - v2 includes batch normalisation before final dense layer\n",
        "    - results were unreadable: input ran out of data and interrupted training.\n",
        "        - steps per epoch needs revision\n",
        "\n",
        "    V3 :\n",
        "    - Findings showed that augmented training data was only used on first batch and was not recalled, hense the input ran out of data on subsequent epochs.\n",
        "    - no early stopping yet - allow full 25 epochs for evaluation first\n",
        "    - when fitting model, steps per epoch were handled directly by keras (which should be the same as train_set.samples // batch_size), but should call augmentation each time.\n",
        "    - TODO Findings:\n",
        "        - this showed no input data running out \n",
        "        - keep early stop\n",
        "\n",
        "    V4 plans: \n",
        "    - TODO deicde add hyperparam optimisation\n",
        "    - TODO CONV layers descending order instead (128 filters, then 64, then 32)\n",
        "\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input layer: CONV1\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
        "        input_shape=image_shape,  # average image shape\n",
        "        activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    # CONV2\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "        activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    # CONV3\n",
        "    model.add(Conv2D(\n",
        "        filters=128,  # increase\n",
        "        kernel_size=(3,3),\n",
        "        activation='relu', ))\n",
        "    # TODO v3: consider adding normalisation here too\n",
        "    # model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    # Flatten\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # TODO v3: Tune the number of units in the first Dense layer\n",
        "    # Choose an optimal value between 32-512\n",
        "    # hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "    # model.add(Dense(units=hp_units, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())  \n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # TODO v3 Tune the learning rate for the optimizer\n",
        "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "    # hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    # Compile\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer='adam',\n",
        "        # TODO edit optimizer=Adam(learning_rate=hp_learning_rate), - import beforehand\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "        ])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Instantiate tuner and perform hypertuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary = create_tf_model().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Early Stopping\n",
        "\n",
        "    * Avoid overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=3)  # increase patience from 3 to 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run hypertune search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO v3\n",
        "# SOURCE https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
        "\n",
        "# tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# # Get the optimal hyperparameters\n",
        "# best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# print(f\"\"\"\n",
        "# The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "# layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "# is {best_hps.get('learning_rate')}.\n",
        "# \"\"\")\n",
        "# _________\n",
        "# # then reinstantiate hyermodel and train it with optimal number of epochs from above\n",
        "# hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# # Retrain the model\n",
        "# hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)\n",
        "# _________\n",
        "\n",
        "# eval_result = hypermodel.evaluate(img_test, label_test)\n",
        "# print(\"[test loss, test accuracy]:\", eval_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visaulise Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "try:\n",
        "    model = create_tf_model()\n",
        "    plot_model(model, show_shapes=True, to_file=f'model_{version}.png')\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO remove before submit\n",
        "print(f'Train set object: {train_set}')\n",
        "print(f\"Number of samples in training set: {train_set.samples}\")\n",
        "print(f\"Number of classes: {len(train_set.classes)}\")\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Current steps calculation (classes/batch_size): {len(train_set.classes) // batch_size}\")\n",
        "print(f\"Correct steps calculation (samples/batch_size): {train_set.samples // batch_size}\")\n",
        "print(f\"Number of validation samples: {validation_set.samples}\")\n",
        "print(f\"Validation steps per epoch: {validation_set.samples // batch_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # TODO remove? Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "# model = tuner.hypermodel.build(best_hps)\n",
        "# history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "# val_acc_per_epoch = history.history['val_accuracy']\n",
        "# best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "# print('Best epoch: %d' % (best_epoch,))\n",
        "\n",
        "model = create_tf_model()\n",
        "\n",
        "model.fit(train_set,\n",
        "          epochs=25,\n",
        "          steps_per_epoch=None, # None is equal to the number of samples in your dataset divided by the batch size\n",
        "          validation_data=validation_set,\n",
        "          validation_steps=None,  #  validation will run until the validation_data dataset is exhausted\n",
        "          #   TODO v4: add back: \n",
        "          callbacks=[early_stop],\n",
        "          verbose=1\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(f'outputs/{version}/cherry-tree-model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*** \n",
        "\n",
        "# Evaluate Model Performance "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # TODO remove if required\n",
        "# import joblib\n",
        "# file = f'/workspace/cherry-ML/outputs/{version}/cherry-tree-model.h5'\n",
        "# model = joblib.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def extract_performance_from_history(model, history):\n",
        "    \"\"\"\n",
        "    Extract and analyze performance metrics from model training history\n",
        "    \n",
        "    Parameters:\n",
        "    - model: Trained Keras model\n",
        "    - history: Model training history object\n",
        "    \n",
        "    Returns:\n",
        "    - Dictionary of performance metrics\n",
        "    \"\"\"\n",
        "    # Extract metrics from history\n",
        "    performance_metrics = {\n",
        "        'training': {\n",
        "            'loss': history.history.get('loss', []),\n",
        "            'accuracy': history.history.get('accuracy', []),\n",
        "            'val_loss': history.history.get('val_loss', []),\n",
        "            'val_accuracy': history.history.get('val_accuracy', [])\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Calculate best epoch and corresponding metrics\n",
        "    best_train_accuracy = max(performance_metrics['training']['accuracy'])\n",
        "    best_val_accuracy = max(performance_metrics['training']['val_accuracy'])\n",
        "    best_train_loss = min(performance_metrics['training']['loss'])\n",
        "    best_val_loss = min(performance_metrics['training']['val_loss'])\n",
        "    \n",
        "    performance_metrics['best_metrics'] = {\n",
        "        'best_train_accuracy': best_train_accuracy,\n",
        "        'best_val_accuracy': best_val_accuracy,\n",
        "        'best_train_loss': best_train_loss,\n",
        "        'best_val_loss': best_val_loss\n",
        "    }\n",
        "    \n",
        "    return performance_metrics\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    Create plots for training and validation metrics\n",
        "    \n",
        "    Parameters:\n",
        "    - history: Model training history object\n",
        "    \n",
        "    Returns:\n",
        "    - Matplotlib figure with subplots\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    plt.figure(figsize=(12, 4))\n",
        "    \n",
        "    # Plot training & validation accuracy values\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "    \n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return plt\n",
        "\n",
        "def print_model_summary(model):\n",
        "    \"\"\"\n",
        "    Print a detailed summary of the model architecture\n",
        "    \n",
        "    Parameters:\n",
        "    - model: Keras model\n",
        "    \"\"\"\n",
        "    # Capture model summary as a string\n",
        "    from io import StringIO\n",
        "    import sys\n",
        "    \n",
        "    # Redirect stdout to capture model summary\n",
        "    old_stdout = sys.stdout\n",
        "    model_summary = StringIO()\n",
        "    sys.stdout = model_summary\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    # Restore stdout and get the summary\n",
        "    sys.stdout = old_stdout\n",
        "    summary_text = model_summary.getvalue()\n",
        "    \n",
        "    print(\"Model Architecture Summary:\")\n",
        "    print(summary_text)\n",
        "    \n",
        "    # Calculate total parameters\n",
        "    total_params = sum([np.prod(K.get_value(w).shape) for w in model.trainable_weights])\n",
        "    trainable_params = sum([np.prod(K.get_value(w).shape) for w in model.trainable_weights])\n",
        "    non_trainable_params = sum([np.prod(K.get_value(w).shape) for w in model.non_trainable_weights])\n",
        "    \n",
        "    print(f\"\\nTotal Parameters: {total_params:,}\")\n",
        "    print(f\"Trainable Parameters: {trainable_params:,}\")\n",
        "    print(f\"Non-Trainable Parameters: {non_trainable_params:,}\")\n",
        "\n",
        "# Example usage:\n",
        "def comprehensive_model_analysis(model, history, train_set, validation_set, test_set, labels):\n",
        "    \"\"\"\n",
        "    Provide comprehensive analysis of model performance\n",
        "    \n",
        "    Parameters:\n",
        "    - model: Trained Keras model\n",
        "    - history: Model training history\n",
        "    - train_set, validation_set, test_set: Data generators\n",
        "    - labels: List of class labels\n",
        "    \"\"\"\n",
        "    # 1. Print model summary\n",
        "    print_model_summary(model)\n",
        "    \n",
        "    # 2. Extract performance metrics\n",
        "    performance_metrics = extract_performance_from_history(model, history)\n",
        "    \n",
        "    # 3. Print performance metrics\n",
        "    print(\"\\n--- Performance Metrics ---\")\n",
        "    for metric, value in performance_metrics['best_metrics'].items():\n",
        "        print(f\"{metric.replace('_', ' ').title()}: {value:.4f}\")\n",
        "    \n",
        "    # 4. Plot training history\n",
        "    plt = plot_training_history(history)\n",
        "    plt.show()\n",
        "    \n",
        "    # 5. Generate confusion matrices\n",
        "    print(\"\\n--- Confusion Matrices ---\")\n",
        "    clf_performance(model, train_set, validation_set, test_set, labels)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot model training loss and accuracy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run analysis\n",
        "extract_performance_from_history(model, model.history.history)\n",
        "plot_training_history(model.history.history)\n",
        "print_model_summary(model)\n",
        "comprehensive_model_analysis(model, history, train_set, validation_set, test_set, labels=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO do I need this as well as the functions above?\n",
        "losses = pd.DataFrame(model.history.history)\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title('Loss')\n",
        "plt.savefig(f'{file_path}/training_loss.png', bbox_inches='tight', dpi=600)\n",
        "print('\\n')\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title('Accuracy')\n",
        "plt.savefig(f'{file_path}/training_accuracy.png', bbox_inches='tight', dpi=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set)\n",
        "try:\n",
        "    evaluation_train = model.evaluate(train_set)\n",
        "    evaluation_val = model.evaluate(validation_set)\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation,\n",
        "            filename=f\"outputs/v1/evaluation.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run Live Prediction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 66  # TODO change to random within length of dir\n",
        "label = labels[1]  # select Uninfected or Parasitised # TODO change to random (0 or 1) and print image class too\n",
        "\n",
        "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
        "                           target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_img = image.img_to_array(pil_image)\n",
        "pred_img = np.expand_dims(pred_img, axis=0)/255\n",
        "print(pred_img.shape)\n",
        "pred_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# predict class probability on test image\n",
        "pred_proba = model.predict(pred_img)[0, 0] # TODO why 0 0?\n",
        "\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "pred_class = target_map[pred_proba > 0.5]\n",
        "\n",
        "if pred_class == target_map[0]:\n",
        "  pred_proba = 1 - pred_proba\n",
        "\n",
        "print(f'Prediction: {pred_class}\\nConfidence: {pred_proba*100:.1f}%') # TODO do I want more decimal places?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*** "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
