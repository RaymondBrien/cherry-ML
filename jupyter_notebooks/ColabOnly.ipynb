{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaymondBrien/cherry-ml/blob/main/jupyter_notebooks/ColabOnly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Notebook for Google Collab**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "# This notebook is for use in Google Collab only, compiled in a single workflow.\n",
        "\n",
        "## Objectives\n",
        "Answer Business requirement 2: Binary Classification using Convolutional Neural Networks\n",
        "\n",
        "* predict if a given leaf is infected or not judging by the presence of powdery mildew.\n",
        "* use the CNN to map relationships between features and labels.\n",
        "* build a binary classifier and generate reports.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/cherry-leaves-dataset/cherry-leaves/train\n",
        "* inputs/cherry-leaves-dataset/cherry-leaves/test\n",
        "* inputs/cherry-leaves-dataset/cherry-leaves/validation\n",
        "* image shape embeddings pickle file\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* cherry-tree-model.h5 (model)\n",
        "* class_distribution.png\n",
        "* class_indices.pkl\n",
        "* model_training_acc.png\n",
        "* model_training_losses.png\n",
        "* test-evaluation.pkl\n",
        "* train-evaluation.pkl\n",
        "* val-evaluation.pkl\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AroaT0QzJjV"
      },
      "source": [
        "### ANNOTATE MODEL VERSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xWcm0ucczJjW"
      },
      "outputs": [],
      "source": [
        "version = 'v6'  # change as needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW-T96GbE4ML"
      },
      "source": [
        "Mount drive for backup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6slN9EjRE000",
        "outputId": "068f2d6a-333c-4ff3-a3a5-a85db14ad82e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33bVN8K0zJjW"
      },
      "source": [
        "### Import regular packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gV2EQ_m1zJjW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "### Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wZfF_j-Bz3i4",
        "outputId": "f0e5c01e-7414-4fe1-c5b6-06590f2cb438"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwHsQRWjz3i9",
        "outputId": "5bfdd49c-78df-468c-a904-92331f433d39"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vz3S-_kjz3jA",
        "outputId": "d08aaf4a-2f52-43d0-a942-cae61b70a69c"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "pkuM6L46zJjY",
        "outputId": "bdb64757-66c0-4da4-9d00-0daf33f6aa70"
      },
      "outputs": [],
      "source": [
        "# manually upload kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vThH9qRszJjY",
        "outputId": "80d4500f-3dac-485e-a427-890563e79eba"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "W5E8UOR5zJjY"
      },
      "outputs": [],
      "source": [
        "# allow kaggle.json access\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoH3btp6zJjY",
        "outputId": "c9e145a1-1c45-42f8-8734-d240e18b5929"
      },
      "outputs": [],
      "source": [
        "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
        "DestinationFolder = \"inputs/cherry-leaves-dataset\"  # creates new dir/dir\n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-2gZxYw0zJjY"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(DestinationFolder + '/cherry-leaves.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall(DestinationFolder)\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSwHq6dQzJjY"
      },
      "source": [
        "### Set input directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7stKmyp_zJjY"
      },
      "outputs": [],
      "source": [
        "my_data_dir = 'inputs/cherry-leaves-dataset/cherry-leaves'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuApLt0VzJjY"
      },
      "source": [
        "### Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IfH8l6JxzJjY"
      },
      "outputs": [],
      "source": [
        "\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
        "    print('Old version is already available, create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJxBAIIWzJjZ"
      },
      "source": [
        "### Gather labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckgIR2B6zJjZ",
        "outputId": "0862580a-c2c8-4cc6-8b4a-7878dec0ffff"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    labels = os.listdir(train_path)\n",
        "except:\n",
        "    labels = ['healthy', 'powdery_mildew']\n",
        "\n",
        "print(f\"Project Labels: {labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPQP9P1YzJjZ"
      },
      "source": [
        "### Load image shape embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3h4cO96zJjZ",
        "outputId": "4458235d-9231-4132-a424-b1ecdffeefa9"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "try:\n",
        "    # Import saved image shape embedding pickle file\n",
        "    image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "\n",
        "except:\n",
        "    # for google collab\n",
        "    image_shape = (256, 256, 3)\n",
        "\n",
        "finally:\n",
        "    print(image_shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO0loRGnzJjZ"
      },
      "source": [
        "## Validate image files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WRSQ6lIPzJjZ"
      },
      "outputs": [],
      "source": [
        "# Uncomment if using google collab\n",
        "\n",
        "def remove_non_image_files(my_data_dir):\n",
        "    print('Removing non image files...\\n')\n",
        "    image_extension = ('.png', '.jpg', 'jpeg')\n",
        "    folders = os.listdir(my_data_dir)\n",
        "    for folder in folders:\n",
        "        files = os.listdir(f'{my_data_dir}/{folder}')\n",
        "        # print files\n",
        "        non_image = []\n",
        "        image_count = []\n",
        "        for given_file in files:\n",
        "            try:\n",
        "                if not given_file.lower().endswith(image_extension):\n",
        "                    file_location = f'{my_data_dir}/{folder}/{given_file}'\n",
        "                    os.remove(file_location) # remove non image file\n",
        "                    non_image.append(1)\n",
        "                else:\n",
        "                    image_count.append(1)\n",
        "                    pass\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "        print(f'Folder: {folder} has - {len(image_count)} image files')\n",
        "        print(f'Folder: {folder} has - {len(non_image)} non image files, which have been removed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm6MsMULzJjZ",
        "outputId": "d748e2c9-8069-4dfa-b5b4-350087b45bff"
      },
      "outputs": [],
      "source": [
        "remove_non_image_files('inputs/cherry-leaves-dataset/cherry-leaves')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFxIhIi_zJjZ"
      },
      "source": [
        "# Split train, val, test sets with dirs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Dx1nuK9qzJjZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
        "\n",
        "    # confirm ratios total 1.0\n",
        "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
        "        print('Ratios should total 1.0.')\n",
        "        print('You entered:\\n')\n",
        "        print(f'Train radio: {train_set_ratio}')\n",
        "        print(f'Validation radio: {validation_set_ratio}')\n",
        "        print(f'Test radio: {test_set_ratio}')\n",
        "        return\n",
        "\n",
        "    # get classes labels\n",
        "    labels = os.listdir(my_data_dir)  # expect only folder name\n",
        "    if 'test' in labels:\n",
        "        pass\n",
        "    else:\n",
        "        try:\n",
        "            # create train, test folders with classes labels sub-folder\n",
        "            for folder in ['train', 'validation', 'test']:\n",
        "                for label in labels:\n",
        "                    os.makedirs(name=f'{my_data_dir}/{folder}/{label}')\n",
        "\n",
        "            for label in labels:\n",
        "\n",
        "                files = os.listdir(f'{my_data_dir}/{label}')\n",
        "                random.seed(42)\n",
        "                random.shuffle(files)\n",
        "\n",
        "                train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "                validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "\n",
        "                count = 1\n",
        "                for file_name in files:\n",
        "                    if count <= train_set_files_qty:\n",
        "                        # move given file to train set\n",
        "                        shutil.move(f'{my_data_dir}/{label}/{file_name}',\n",
        "                                    f'{my_data_dir}/train/{label}/{file_name}')\n",
        "                    elif count <= (train_set_files_qty + validation_set_files_qty):\n",
        "                        # move a given file to the validation set\n",
        "                        shutil.move(f'{my_data_dir}/{label}/{file_name}',\n",
        "                                    f'{my_data_dir}/validation/{label}/{file_name}')\n",
        "                    else:\n",
        "                        # move given file to test set\n",
        "                        shutil.move(f'{my_data_dir}/{label}/{file_name}',\n",
        "                                    f'{my_data_dir}/test/{label}/{file_name}')\n",
        "\n",
        "                    count += 1\n",
        "\n",
        "                os.rmdir(f'{my_data_dir}/{label}')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "    print('Done!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLlnrU3OzJja",
        "outputId": "74e2a0c2-f6d1-47d8-a030-5f4f89f2f4db"
      },
      "outputs": [],
      "source": [
        "split_train_validation_test_images(\n",
        "    my_data_dir='inputs/cherry-leaves-dataset/cherry-leaves',\n",
        "    train_set_ratio=0.7,\n",
        "    validation_set_ratio=0.1,\n",
        "    test_set_ratio=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S4ltCfIzJja"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgP3xFzlzJja"
      },
      "source": [
        "# Review class distribution\n",
        "\n",
        "* across whole dataset\n",
        "* per train, test, and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "jwjePPAXzJja",
        "outputId": "d30f7ba1-570a-49e5-fc8e-86e2d257e711"
      },
      "outputs": [],
      "source": [
        "df_freq = pd.DataFrame([])\n",
        "total_images_count = 0\n",
        "\n",
        "\n",
        "# gather info\n",
        "for folder in ['train', 'validation', 'test']:\n",
        "    for label in labels:\n",
        "\n",
        "        path = my_data_dir + '/' + folder + '/' + label\n",
        "\n",
        "        image_count = int(len(os.listdir(path)))\n",
        "        total_images_count += image_count\n",
        "\n",
        "        # Create a new DataFrame with the data for the current row\n",
        "        new_row = pd.DataFrame({'Set': [folder], 'Label': [label], 'Frequency': [image_count]})\n",
        "\n",
        "        # Concatenate the new row to the existing DataFrame\n",
        "        df_freq = pd.concat([df_freq, new_row], ignore_index=True)\n",
        "\n",
        "        print(f\"* {folder}- {label}: {image_count} images\\n\")\n",
        "\n",
        "\n",
        "print(f'{total_images_count} images total')\n",
        "print('--------')\n",
        "\n",
        "### plot class distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.set_style('darkgrid')\n",
        "sns.barplot(x='Set', y='Frequency', hue='Label', data=df_freq, )\n",
        "            # color='Frequency' alpha=\"Frequency\", edgestyle='Frequency'\n",
        "plt.title('Class Distribution')\n",
        "plt.savefig(f'{file_path}/class_distribution.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "print('\\n')\n",
        "\n",
        "print('--------')\n",
        "\n",
        "# confirm percentages of dataset\n",
        "df_freq.set_index('Label', inplace=True)\n",
        "df_freq['Percent of DataSet'] = round(df_freq['Frequency'] / total_images_count * 100)\n",
        "\n",
        "print(df_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5FxuIvWzJja"
      },
      "source": [
        "We can confirm that train, validation and test set percentages of dataset are split as expected, and that there are equal amounts of both classes (healthy and powdery_mildew) in each set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct3x8EcazJjh"
      },
      "source": [
        "# Image Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0c4239gzJjh"
      },
      "source": [
        "### Define image data generator, initialize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "37QwYscxzJjh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Initialize\n",
        "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
        "                                          width_shift_range=0.1,\n",
        "                                          height_shift_range=0.1,\n",
        "                                        #   brightness_range=[0.8, 1.2],\n",
        "                                          shear_range=0.1,\n",
        "                                          zoom_range=0.1,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=True,\n",
        "                                          fill_mode='nearest',\n",
        "                                          rescale=1./255\n",
        "                                          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9exJClPzJji"
      },
      "source": [
        "### Define batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "5YDWgy4jzJji"
      },
      "outputs": [],
      "source": [
        "batch_size = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO3-gbntzJji"
      },
      "source": [
        "### Augment TRAINING image dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhK7IXrWzJji",
        "outputId": "0b72be75-d20b-4354-b0c3-e10f53a2f518"
      },
      "outputs": [],
      "source": [
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='binary',\n",
        "                                                     shuffle=True,\n",
        "                                                     # seed=42,\n",
        "                                                     )\n",
        "\n",
        "\n",
        "train_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahJzKsmvzJji"
      },
      "source": [
        "### Rescale validation image dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRdG9lYbzJji",
        "outputId": "13285764-d98f-4bfe-d502-71b7dbec5459"
      },
      "outputs": [],
      "source": [
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
        "                                                          target_size=image_shape[:2],\n",
        "                                                          color_mode='rgb',\n",
        "                                                          batch_size=batch_size,\n",
        "                                                          class_mode='binary',\n",
        "                                                          shuffle=False\n",
        "                                                          )\n",
        "\n",
        "validation_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqvXkKLzJji"
      },
      "source": [
        "### Rescale test image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61ITqUoCzJjj",
        "outputId": "4a4817b1-f075-4ace-ed1e-42c4038121d4"
      },
      "outputs": [],
      "source": [
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                    target_size=image_shape[:2],\n",
        "                                                    color_mode='rgb',\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='binary',\n",
        "                                                    shuffle=False\n",
        "                                                    )\n",
        "\n",
        "test_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s_3z1CwzJjj"
      },
      "source": [
        "### Plot augmented training images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dQ3HasFCzJjj",
        "outputId": "2609a09f-b8fb-42dc-9dcb-0cb8ae76a4d0"
      },
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    try:\n",
        "        img, label = train_set.next()\n",
        "    except:\n",
        "        # for google collab functionality\n",
        "        img, label = next(train_set)\n",
        "\n",
        "    print(f'{img.shape}\\n')  # expect: (20, 256, 256, 3)\n",
        "    plt.imshow(img[0])\n",
        "    print('--------------')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3Yldd9vzJjj"
      },
      "source": [
        "### Plot augmented validation and test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L8G62rR1zJjj",
        "outputId": "e79b8de0-6d36-4096-c205-c5e299663774"
      },
      "outputs": [],
      "source": [
        "# validation_set\n",
        "for _ in range(3):\n",
        "    try:\n",
        "        img, label = validation_set.next()\n",
        "    except:\n",
        "        # for google collab functionality\n",
        "        img, label = next(validation_set)\n",
        "    print(f'{img.shape}\\n')\n",
        "    plt.imshow(img[0])\n",
        "    print('--------------')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l8yqf6zaiB3z",
        "outputId": "19d25948-4c28-40bf-fbcf-407f13e2c31a"
      },
      "outputs": [],
      "source": [
        "# test set\n",
        "for _ in range(3):\n",
        "    try:\n",
        "        img, label = test_set.next()\n",
        "    except:\n",
        "        # for google collab functionality\n",
        "        img, label = next(test_set)\n",
        "    print(f'{img.shape}\\n')\n",
        "    plt.imshow(img[0])\n",
        "    print('--------------')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD9s1L0LzJjj"
      },
      "source": [
        "###  Observations\n",
        "Augmented validation and test images have been standardized between 0 to 255 pixels. As you can see, the images are ugmented and are ready to be used for developing and training a CNN model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly21xrMIzJjj"
      },
      "source": [
        "### Save class indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy-eirdezJjj",
        "outputId": "5699d32a-80af-4abc-b9e8-6747b6e18cf2"
      },
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYcOKiHozJjk"
      },
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5tQIVmYzJjk"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEPAa_oUzJjk"
      },
      "source": [
        "### ML Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz-4RL2-zJjk"
      },
      "source": [
        "* Import model packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "xw3xZMwWzJjl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noJbQZ5lzJjl"
      },
      "source": [
        "* ### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "FUeOmUBCzJjl"
      },
      "outputs": [],
      "source": [
        "def create_tf_model():\n",
        "    \"\"\"\n",
        "    Creates a CNN model for binary classification of leaf images\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input layer: CONV1\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
        "        input_shape=image_shape,  # average image shape\n",
        "        activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    # CONV2\n",
        "    model.add(Conv2D(filters=12, kernel_size=(3, 3),\n",
        "        activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    # CONV3\n",
        "    model.add(Conv2D(filters=8, kernel_size=(3,3),\n",
        "        activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    # Flatten\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer='adam',\n",
        "        metrics=['accuracy',])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKzk1vWezJjl"
      },
      "source": [
        "## Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "y30xtcgizJjl",
        "outputId": "b671a10b-67b6-4129-bc90-ab0b548f01d8"
      },
      "outputs": [],
      "source": [
        "summary = create_tf_model().summary(show_trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WESlHYfvzJjm",
        "outputId": "2f2498c6-6d36-4011-f577-5eea478a4693"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    plot_model(model, show_shapes=True, to_file=f'model_{version}.png')\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "356nr8ctzJjl"
      },
      "source": [
        "Early Stopping\n",
        "* Avoid overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "qR8F8aTXzJjm"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgjeIiWEzJjm"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWZ605CrzJjm",
        "outputId": "7f9a379d-531e-4938-f680-c821253b6f11"
      },
      "outputs": [],
      "source": [
        "print(f'Train set object: {train_set}')\n",
        "print(f\"Number of samples in training set: {train_set.samples}\")\n",
        "print(f\"Number of classes: {len(train_set.classes)}\")\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Current steps calculation (classes/batch_size): {len(train_set.classes) // batch_size}\")\n",
        "print(f\"Correct steps calculation (samples/batch_size): {train_set.samples // batch_size}\")\n",
        "print(f\"Number of validation samples: {validation_set.samples}\")\n",
        "print(f\"Validation steps per epoch: {validation_set.samples // batch_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZGZJyI6zJjn"
      },
      "source": [
        "# Fit Model for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzPFyxWAzJjn"
      },
      "source": [
        "### Save checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "2i2g_zBazJjn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# check if the full path exists\n",
        "checkpoint_folder = f'/workspace/outputs/{version}/training_checkpoints'\n",
        "\n",
        "if not os.path.exists(checkpoint_folder):\n",
        "    os.makedirs(checkpoint_folder)\n",
        "    print('training checkpoints folder made')\n",
        "\n",
        "# dynamically include the epoch in checkpoint file name\n",
        "checkpoint_path = f\"{checkpoint_folder}/cp-{{epoch:04d}}.weights.h5\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# callback to save model weights per epoch\n",
        "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 verbose=1,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 save_freq='epoch',\n",
        "                                                 monitor='accuracy',\n",
        "                                                 save_best_only=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdgDVG7yzJjn"
      },
      "source": [
        "Brief untrained model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuGeaG49zJjn",
        "outputId": "ff774931-9718-4ac3-8553-8f182ba1dea6"
      },
      "outputs": [],
      "source": [
        "loss, acc = create_tf_model().evaluate(test_set, verbose=2)\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc)) # expect c.50% accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv0ELu76iB33"
      },
      "source": [
        "Add CSV logger for history access in case of training runtime errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "5L9fTgl8QFhp"
      },
      "outputs": [],
      "source": [
        "history_csv_logger = CSVLogger('training.log', separator=',', append=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define epoch count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYHPOYepzJjn",
        "outputId": "85b10bdd-9860-430a-ecd7-4a3221b63e94"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    model = create_tf_model()\n",
        "    model.fit(train_set,\n",
        "            epochs=EPOCHS,\n",
        "            steps_per_epoch = len(train_set.classes) // batch_size,\n",
        "            validation_data=validation_set,\n",
        "            callbacks=[early_stop, cp_callback, history_csv_logger],\n",
        "            verbose=1,\n",
        "            )\n",
        "except Exception as e:\n",
        "    print(e + '\\n')\n",
        "\n",
        "    # load latest weights\n",
        "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "    model.load_weights(latest)\n",
        "\n",
        "    print('Model restored! Continuing...')\n",
        "    # continue model training\n",
        "    model.fit(train_set,\n",
        "            epochs=EPOCHS,\n",
        "            steps_per_epoch = len(train_set.classes) // batch_size,\n",
        "            validation_data=validation_set,\n",
        "            callbacks=[early_stop, cp_callback, history_csv_logger],\n",
        "            verbose=1,\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW8MY9eRzJjo"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_bE4TvTzJjo",
        "outputId": "cf05cfe6-4501-42b1-b2fe-85b113c5aa30"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    model.save(f'outputs/{version}/cherry-tree-model.h5')\n",
        "    print('model saved!')\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go4rNuq8zJjo"
      },
      "source": [
        "***\n",
        "\n",
        "# Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpOAkYRniB34"
      },
      "source": [
        "Model learning curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "GZZ90ZJ1iB34",
        "outputId": "4e8cf939-615f-452f-b05a-bf156e1c5dc5"
      },
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "losses[['loss','val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy','val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD7Gw6pUzJjo"
      },
      "source": [
        "### Evaluate and save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtQqAlH1iB34",
        "outputId": "1808115d-c76b-415e-c5aa-00cec7748c61"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(f'{file_path}/cherry-tree-model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQU1zQuqzJjp",
        "outputId": "82e87c11-dc90-43b0-9e56-0c7214e96afc"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    eval1 = model.evaluate(test_set)\n",
        "    evaluation_train = model.evaluate(train_set)\n",
        "    evaluation_val = model.evaluate(validation_set)\n",
        "except Exception as e:\n",
        "    eval1 = model.evaluate(test_set)  # evaluate on test set only\n",
        "    print(e)\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChIBqkcQiB35"
      },
      "source": [
        "Save evaluations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgiZ5qGczJjp",
        "outputId": "5f871cd6-6042-44f7-e949-62166939db2c"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    joblib.dump(value=eval1,filename=f\"outputs/{version}/test-evaluation.pkl\")\n",
        "    joblib.dump(value=evaluation_train,filename=f\"outputs/{version}/train-evaluation.pkl\")\n",
        "    joblib.dump(value=evaluation_val,filename=f\"outputs/{version}/val-evaluation.pkl\")\n",
        "except Expection as e:\n",
        "    print(e)\n",
        "    print('-----')\n",
        "    print('saving successful test eval')\n",
        "    joblib.dump(value=eval1,filename=f\"outputs/{version}/test-evaluation.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdJ4bzPPFQSQ"
      },
      "source": [
        "Save backup model to drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxrteroXFA7O",
        "outputId": "e34156fb-4f3f-4bb4-e0e5-38771e7f2c2c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp -r outputs/{version} /content/drive/MyDrive/{version}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf4mwhVVzJjp"
      },
      "source": [
        "# Run Live Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDzd2Y8GiB35"
      },
      "source": [
        "Load image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "L6gBOGOLzJjp",
        "outputId": "237a902f-ebc2-400d-a458-33c854c0eae0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 66  # choose random int\n",
        "label = labels[1]  # choose 0 or 1 (healthy, infected)\n",
        "\n",
        "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
        "                           target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmruXWagiB36"
      },
      "source": [
        "Convert prediction image to array for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXffSnQ6zJjp",
        "outputId": "063a3f33-5980-4dc7-f37a-e9676859c0b5"
      },
      "outputs": [],
      "source": [
        "pred_img = image.img_to_array(pil_image)\n",
        "pred_img = np.expand_dims(pred_img, axis=0)/255\n",
        "print(pred_img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PskpX80PiB36"
      },
      "source": [
        "Predict class probability on test image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-VIzIUCzJjp",
        "outputId": "79e685a9-2243-458a-f904-635b5482d75b"
      },
      "outputs": [],
      "source": [
        "pred_proba = model.predict(pred_img)[0, 0]\n",
        "\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "pred_class = target_map[pred_proba > 0.5]  # define binary boundary\n",
        "\n",
        "if pred_class == target_map[0]:\n",
        "  pred_proba = 1 - pred_proba\n",
        "\n",
        "print(f'Prediction: {pred_class}\\nConfidence: {pred_proba*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdNTYa9sFUPX"
      },
      "source": [
        "## Save backup files to drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odGO2VsiIvsv"
      },
      "source": [
        "Save tf version used in notebook to file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yaHyjcLFVoq",
        "outputId": "a4bcadbc-383a-4801-a406-c3acb0e7b57f"
      },
      "outputs": [],
      "source": [
        "tf_version = tf.__version__\n",
        "tf_version\n",
        "\n",
        "joblib.dump(value=tf_version,filename=f\"outputs/{version}/tf_version.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "-5qQ9loQItTH"
      },
      "outputs": [],
      "source": [
        "!pip freeze > outputs/{version}/colab_requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wwDXC5ciB37"
      },
      "source": [
        "Reconfirm all files saved in backup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCjGMwySDr-z",
        "outputId": "ace0748b-ce9a-4b90-98d2-7c8727ea6c42"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "!cp -r outputs/{version} /content/drive/MyDrive/{version}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGaiOZfQzJjp"
      },
      "source": [
        "***"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
